                                                                   5.29 CPU相关知识
cpu-analysis
    sy：做上下文切换（自愿上下文切换―可能存在内存瓶颈，非自愿上下文切换―cpu瓶颈，抢占自愿）
    us/in：用户运行计算―cpu密集计算
    si：软中断―cpu竞争抢占自愿或者自愿不够IO问题
    wa：等待自愿―io问题（磁盘/网络）
    st：抢占自愿
load average值与cpu使用率之间的关系
    load average是系统的整体负载体现，包裹：cpu负载+disk负载+网络负载+外设负载，load average = cpiload+ioload
cpu使用：用户进程使用的us，系统内核运行时间sy，空闲时间idle，管理被抢占时间st
    繁忙：us+sy+st+ni+hi+si=cpu使用率
    空闲：idle+wa
load average与cpu高时，使用top查看
    情况1，sys系统态高。排查cpu上下文切换
         如果非自愿上下文切换多，说明cpu不够用，进程时间片到被迫切换
         如果自愿上下文切换多，说明计算用的自愿不够，可能存在IO，内存瓶颈
   情况2，si软中断高，cpu抢自愿，自愿不够用IO问题
          sys高+si高，内存或者网络IO问题
          sys高+si不高   cpu瓶颈
    情况3，us用户太高，用户程序计算
          密集型计算，内存PGC自愿等待


                     6.1 搭建监控平台  grafana+promentheus+硬件资源监控
安装grafana 
      需要安装到非被测服务器
      安装：yum install grafana-***.rpm -y  (自己上传包)
      启动：systemctl restart grafana-server
      访问地址：http://server_ip:3000  admin/admin

安装prometheus 是一个时序数据库
      需要安装到非北侧服务器
      tar -xzvf prometheus-2.17.1.linux-amd64.tar.gz（自己上传包）
      进入解压文件夹后启动：./promethues
      访问地址：http://server_ip:9090

安装node_export（用于收集硬件资源）
       需要安装到被测服务器上
       tar -xzvf node_exporter -1.1.1.linux-amd6464.tar.gz（自己上传包）
       进入解压文件启动：./node_exporter
      访问地址http://server_ip:9100
 
promethues+node_export配置
   修改prometheus配置文件prometheus.yml
          - job_name: 'node_exporter'
            static_configs:
                - targets:['http://server_ip:9100']
    重启prometheus

grafana+prometheus配置
    grafana中：
    1.add you data source 选择prometheus ，rul：http://yourprometheus_ip:9090，点击save&test
    2.点击左侧+号选择
       import 引入模板
          8919
       选择数据源为上一步添加的datasource 


CPU实战
     安装stresse-ng（是服务器cpu性能压测工具，模拟系统压力）
         yum install -y epel-release.noarch && yunm -y update
         yum install -y stress-ng
   实操
         步骤1:（（proc_cnt = `nproc*10`））stress-ng --cpu $proc_cnt --pthread 1 --timeout 150：该命令会启动N*10个进程，再只有N个核的系统上，会产生大量的进程切换，模拟                     进程间竞争CPU的场景,此时load average一直升高，系统负载再升高
         步骤2：top命令查看
         步骤3：vmstat 1， proce r列有非常大的数据，说明有大量的cpu竞争，处于等待状态
                         system: in字段，中断信息有明显的数据，cs上下文切换也有明显的数据
         步骤4：pidstat -u -w 1 查看自愿/非自愿上下文是否大，如果大就增加cpu，或者再这台机器上减少进程
         当企业中的实际项目，出现上述情况，我们可以理解为，进程上下文切换比较多
               解决办法：项目所在的服务器，要么减少运行中的进程，要么增加cpu的数量




                                                                6.3 线程上下文切换
 实操
   步骤1：stress-ng --cpu  `nproc`  --pthread 1024 -- timeout 60 该命令会在N个CPU核的系统上，产生N个进程，
   步骤2：top，load average升高， us+sy约等于100%  us低一点，sy高一点（与进程模拟的相反）
   步骤3： vmstat 1，procs中r列有大量的数据，说明cpu竞争大
                   system：in字段，中断有大量的数据，cs上下文切换也有大量的数据
                   memory：free明显变小，buffer基本不变，cache变大
                          free：内存空闲空间，内存消耗增大
                          buffer：buffer是磁盘虚拟出来的，用于内存从磁盘读数据时使用
                          cache：内存虚拟出来的，用于cpu与内存速度匹配
   步骤4：pidstat -u -w -1，自愿上下文切换比较多，非自愿上下文切换相对较少
   当企业中一个程序开启了大量的线程，就会使用大量的内存资源，就会出现有大量的cpu竞争（从内存中获取数据，当获取不到数据时，既读写跟不上，io问题）sy比us高，r队列有大量      的等待，有大量的上下文切换且自愿上下文切换比较多（资源不够就会出现自愿切换）
   解决办法：减少线程数或者选择速度更高的内存条，更换使用缓存更大的cpu

                                                       6.3 load average = cpu负载+io负载
企业中项目，应用服务器和数据服务器时部署再不同的服务器上，因为他们的性能关注点时不一样的，应用服务器要进行大量的计算，关注的性能的计算能力，数据库服务器，是要读写数据到数据库中，有大量的磁盘读写，关注性能是磁盘读写能力

io负载，导致系统负载比较高
实操
   步骤1：stress-ng -i 6 --hdd 1 --time 150，该命令开启1个worker不停的读写临时文件，同事启动6个worker不停的调用sync系统调用提交缓存
   步骤2：top，load average升高，us与sy基本没有变化，cpu的wa值变大约等于100%，memory的free较少，buff/cache变大
   步骤3：vmstat 1，memory的free变小，buff基本不边，cache变大，io的bi，bo有数据，bo值变大，cpu的in和cs变大
   步骤4：mpstat -P -ALL 1，%iowait变大
   步骤5：pidstat -w 1， 自愿上下文切换数据要大于非自愿上下文切换
   企业中项目出现上述情况，如何解决
         1.更换读写速度更快的磁盘，2加大内存

                                                            6.3-6.5内存知识
内存：是cpu与其他设备沟通的桥梁，主要用来临时存放数据，配合cpu工作，协调cpu的处理速度
        硬盘数据，外设数据，网络传输数据，要进入cpu前，都要先进入内存
        临时存放，再断电后，内存内容就会丢失
内存的组成：内存地址，存储单元
     关系：门派号与家庭房屋，门牌找到家庭地址（内存地址），房屋能装人和各种物品（存储单元）

数据结构
   栈：后进先出
   队列（queue）：先进显出
       顺序队列
       循环队列
  堆：存储的是对象（二叉树，B树，红黑树）

链表
   列表：再内存中，会分配一个连续地址空间，存放数据

内存的使用
    内存空间中至少会有一块栈区和一块堆区，栈区存放程序中的变量，堆区存放程序中的对象

jvm
   内存泄露：程序运行时，申请内存空间，但使用完后未及时释放，导致可申请的内存空间越来越少，可以使用的内存空间越来越少
   内存溢出：要申请空间时，没有足够的空间可被申请

栈内存：存储局部变量，变量有一定的作用域，离开作用域，空间就会被释放，更新速度快，生命周期短
堆内存：存储数组和对象，凡是ne出来的都存储再堆里，
内存空间的释放：GC资源回收
堆的一些名词信息
    -Xms  初始堆大小
    -Xmx  最大堆空间
    -Xmn  设置新生代大小
    -XX:SurivivorRatio  新生代eden空间，from空间，to空间的比例关系
    -XX:MaximPermSize  方法去最大值
    -XX:MetaspaceSize   元空间GC阔值
    -XX:MaxmetaspaceSize 元空间GC阔值
    -Xss: 栈大小
    -XX:MaximPermSizeDireMemorySize  直接内存大小，默认为最大堆空间


                                                            6.8 内存性能实战
内存分析命令
   free 
   jmap  
      -dump  生产java对战的快照信息
      -heap    显示java堆详细信息，使用哪种回收机制，参数配置，分代情况
      -histo    显示堆中对象统计信息，包括类，实例熟练
      -jmp -F -dump:format=b,file=文件名.bin 进程id          
           -dump获取java对战信息   format使用格式为二进制  file输出到哪个文件，文件格式为.bin的后缀文件     
   arthas  需要命令安装 curl -O https://arthas.ailiyun.com/arthas-boot.jar   启动 java -jar arthas-boot.jar   面板：dashboard -hd
   heapdump
      在使用mat打开hprof文件时，这个文件一定是要一个完整的文件

jvm分析
      在tomact的catalina.sh文件配置以下信息
      输出gc日志，jvm的启动参数中加入：-XX:+PrimtGC -XX:+PRINTGCDetails -XX:PrintGCTimestamps -XX:+PrintGCApplicationStpopedTime
      启动后输出：GC概要信息，详细信息，gc世界，gc造成的应用暂停世界

                                                               6.8磁盘相关知识+实战
文件IO
    读写不同，io不同
          是否利用标准缓存，缓存io与非缓存io
          是否利用页缓存，直接io和非直接io 
                 直接io：跳过操作系统的页缓存，直接与文件系统交互访问文件
                 非直接io：文件读写时，先给页缓存，再由内核调用，写入磁盘
          是否阻塞自身运行，阻塞io和非阻塞io   
                 阻塞io：如果没有获得响应就阻塞当前线程
                 非阻塞io：不阻塞当前线程
          是否等待响应结果，同步io与异步io
                 同步io：要一直等待整个io完成，才能获得io响应
                 异步io：不等待io完成，可以执行另外的

命令分析
    iostat -dx 2   没两秒收集一次数据
        rrqm/s：每秒进行merge的读操作数目
        wrqm/s：每秒进行merge的写操作数目
        r/s：每秒完成的读IO设备次数
        w/s：每秒完成的写io设备次数
        rsec/s：每秒读扇区数
        wsec/s：每秒写扇区数
        rkB/s：每秒读K字节数
        wkB/s：每秒写k字节数

磁盘性能指标
      使用率：指磁盘处理IO的时间百分比
      饱和度：磁盘处理io的繁忙程度
      IOPS：每秒读写的io请求
      吞吐量： 每秒的io请求大小
      响应时间：指IO请求从发出到响应的时间间隔


实战：
   1.清空页缓存，目录项目，节点
       echo +数字 > /proc/sys/vm/drop_caches
           echo 1 > /proc/sys/vm/drop_caches  释放页缓存
           echo 2 > /proc/sys/vm/drop_caches  释放目录项
           echo 3 > /proc/sys/vm/drop_caches  释放页缓存，目录项，节点  （一般用这个）
           执行完后，buff会为0，cache会减少，free增大
   2.进行磁盘写操作
        dd if=/dev/zero of=$pwd/outfile bs=20MB count=100   （此命令是测试当前磁盘的读写速度）
             解释：/dev/zero  是一个虚拟设备，只产生字符流
                     if 输入
                     of 输出   %pwd当前路径  outfile自己定义的文件名称
                     bs 交换的字节流  2020MB
                     count=100  执行100次总共产生200MB大小的文件
         写文件时：
              vmstat 1 free 命令查看
                  free数据变小，buff数据没变，cache数据变大，bo数据比较大；r/s没有数据，w/s数据变大，rkB/s没有数据，wkB/s数据变大
                   cache是内存虚拟出来的，用于写入数据时加快速度，所以写数据时cache会变大
              iostat -dx 1命令查看
                  r/s没有数据  wKB/s  有大量的数据，说明有大量的磁盘写操作
              top命令查看
                   wa这个指有明显数据 
              分析：实际项目中使用iostat命令，查看到有大量的写操作，wKB/s的数据与磁盘的写数据(磁盘写入的数据通过dd命令算出来的)相近时，说明磁盘写速度，已经成为了项目的性能瓶颈
   3.进行磁盘读操作
           dd if=/dev/sda of=dev/null bs=20MB count=100
                解释：if输入文件，of输出文件
                          /dev/sda   磁盘第一个物理分区，读取这个磁盘文件，会有IO
                          /dev/null    一个虚拟设备，用来当回收站无线存放数据
                          bs=20MB  count=100  文件20MB执行100次
           读文件时：
                 vmstat 1 命令查看
                        free变小了，空闲内存变小，buffer明显变大，cache数据没有明显变化，bi也有明显的数据 
                 bi数据，经过几次增加后，buffer数据页相应的增加，当bi数据没有时，buffer数据页变化，但是此时的读操作并没有结束，说明后面的读数据来自于buffer
                        buffer是由磁盘虚拟出来的，用于加快磁盘的读的速度， 所以再读数据时buffer会变大
                 iostat -dx 1命令查看
                        rkB/s有数据   
   4.测试内存的速度也可以上述方法
          echo 3 > /proc/sys/vm/drop_caches
          dd if=/dev/zero of=dev/null bs=20MB count=100  可以得到内存速度，速度远比磁盘快，可能会上百倍
   5.磁盘性能优化
          1.机械磁盘转为固态硬盘
          2.减少磁盘的io次数，方案：优化代码少读磁盘，减少数据库的查询次数，可以适当加大内存
    6.磁盘项目整体分析
          1.top命令查看，如果cpuwa值比较大，说明有大量的iowait，问题一般是io性能遇到瓶 ，load  avg  过去1分钟的值在升高，系统的负载在升高
          2.vmstat 1命令查看  proc中的r列有数据，说明有队列等待，free数据变小，cache变大，bo一直有数据，说明有大量的写操作――io问题是应该写磁盘瓶颈
          3.iostat -dx 1 wKB/s 数据上有明显的数据，再次证明，存储写io的性能瓶颈
          4.解决问题：
               1.更换磁盘，使用更好的io性能的磁盘
               2.代码优化